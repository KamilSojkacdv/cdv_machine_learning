{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kopia notatnika final model",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "We_Gu4SJmpdt"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from imblearn.pipeline import Pipeline\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3uwfEVBm4wO"
      },
      "source": [
        "def load_test_data():\n",
        "  #import test dataset\n",
        "  path_test = \"/content/drive/MyDrive/ml/test_data.csv\"\n",
        "  test_data = pd.read_csv(path_test, header=None)\n",
        "\n",
        "  return test_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yG4J1Bdam8X9"
      },
      "source": [
        "def load_train_data():\n",
        "  #import train dataset\n",
        "  path_train = \"/content/drive/MyDrive/ml/train_data.csv\"\n",
        "  train_data = pd.read_csv(path_train, header=None)\n",
        "\n",
        "  return train_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHy6g-7SnAGf"
      },
      "source": [
        "def load_labels():\n",
        "  #import labels\n",
        "  path_labels = \"/content/drive/MyDrive/ml/train_labels.csv\"\n",
        "  labels = pd.read_csv(path_labels, header=None)\n",
        "\n",
        "  return labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyAwwkwqyXcM"
      },
      "source": [
        "# print on screen result of score, confusion matrix and classification report\n",
        "def baseline(X_train, X_test, y_train, y_test):\n",
        "  dummy_clf = DummyClassifier()\n",
        "  dummy_clf.fit(X_train, y_train)\n",
        "  score_dummy=(dummy_clf.score(X_train, y_train))  \n",
        "  pred_dummy = dummy_clf.predict(X_test) \n",
        "  print(f'Baseline score: {score_dummy}')\n",
        "\n",
        "  result_confusion_matrix = confusion_matrix(y_test, dummy_clf.predict(X_test))\n",
        "  print(f'confusion_matrix:\\n{result_confusion_matrix}')\n",
        "\n",
        "  result_classification_report = classification_report(y_test,pred_dummy)\n",
        "  print(f'classification_report:\\n{result_classification_report}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9cwNxsyI157"
      },
      "source": [
        "# train model and print on screen confusion matrix and classification report\n",
        "def training_model(X_train, X_test, y_train, y_test):\n",
        "  training_model = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
        "                colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
        "                learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
        "                min_child_weight=1, missing=None, n_estimators=50, n_jobs=1,\n",
        "                nthread=None, objective='binary:logistic', random_state=0,\n",
        "                reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
        "                silent=None, subsample=1, verbosity=1)\n",
        "  training_model.fit(X_train, y_train)\n",
        "  # make predictions for test data\n",
        "  training_y_pred = training_model.predict(X_test)\n",
        "\n",
        "  result_confusion_matrix = confusion_matrix(y_test, training_y_pred)\n",
        "  print(f'confusion_matrix:\\n{result_confusion_matrix}')\n",
        "\n",
        "  result_classification_report = classification_report(y_test,training_y_pred)\n",
        "  print(f'classification_report:\\n{result_classification_report}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bn37YMcS2x3i"
      },
      "source": [
        "def predict_model(X_train, y_train, test_data):\n",
        "  model = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
        "                colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
        "                learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
        "                min_child_weight=1, missing=None, n_estimators=50, n_jobs=1,\n",
        "                nthread=None, objective='binary:logistic', random_state=0,\n",
        "                reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
        "                silent=None, subsample=1, verbosity=1)\n",
        "  # make predictions for test data\n",
        "  model.fit(X_train, y_train)\n",
        "  y_pred = model.predict(test_data)\n",
        "\n",
        "  return y_pred\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiLG_9pEo6Wr"
      },
      "source": [
        "# save dato to csv file\n",
        "def save_data(data, file_name):\n",
        "  # create dataframe of data\n",
        "  df_data = pd.DataFrame(data)\n",
        "  # saving the dataframe \n",
        "  df_data.to_csv(file_name) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cvz2X-R9twuM"
      },
      "source": [
        "def Main():\n",
        "\n",
        "  drive.mount('/content/drive')\n",
        "  \n",
        "  test_data = load_test_data()\n",
        "\n",
        "  train_data = load_train_data()\n",
        "\n",
        "  labels = load_labels()\n",
        "\n",
        "  #assign X, y to data\n",
        "  X, y = train_data, labels\n",
        "\n",
        "  #test train split\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, stratify=y)\n",
        "\n",
        "  print(\"Baseline\\n\")\n",
        "  baseline(X_train, X_test, y_train, y_test)\n",
        "\n",
        "  print(\"Training model\\n\")\n",
        "  training_model(X_train, X_test, y_train, y_test)\n",
        "\n",
        "  y_pred = predict_model(X_train, y_train, test_data)\n",
        "\n",
        "  save_data(y_pred, 'y_pred.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZjGStZ7vM7B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad00bc10-d465-451e-de0a-d17cfaacaccc"
      },
      "source": [
        "Main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Baseline\n",
            "\n",
            "Baseline score: 0.8117038216560509\n",
            "confusion_matrix:\n",
            "[[  11  113]\n",
            " [ 111 1003]]\n",
            "classification_report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.06      0.06      0.06       124\n",
            "           1       0.90      0.89      0.90      1114\n",
            "\n",
            "    accuracy                           0.81      1238\n",
            "   macro avg       0.48      0.48      0.48      1238\n",
            "weighted avg       0.81      0.81      0.81      1238\n",
            "\n",
            "Training model\n",
            "\n",
            "confusion_matrix:\n",
            "[[ 111   13]\n",
            " [  18 1096]]\n",
            "classification_report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.86      0.90      0.88       124\n",
            "           1       0.99      0.98      0.99      1114\n",
            "\n",
            "    accuracy                           0.97      1238\n",
            "   macro avg       0.92      0.94      0.93      1238\n",
            "weighted avg       0.98      0.97      0.98      1238\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}